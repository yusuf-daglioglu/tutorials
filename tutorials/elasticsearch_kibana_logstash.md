# ELASTICSEARCH KIBANA LOGSTASH

IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII

IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII

## ğŸ“Œ ELK (âŸ· Elastic Stack)

`Elasticsearch`, `Logstash` ve `Kibana` Ã¼Ã§lÃ¼sÃ¼ Ã§oÄŸu zaman birlikte kullanÄ±lÄ±yor. bu sebeple bu Ã¼Ã§lÃ¼ pakete verilen kÄ±saltma.

`Logstash`'e her uygulama log'u yollar, `Logstash` tÃ¼m veriyi `Elasticsearch`'e aktarÄ±r. `Kibana` ise `Elasticsearch`'ten okuduÄŸu data'larÄ± son kullanÄ±cÄ±ya web arayÃ¼zÃ¼nden gÃ¶sterir.

Bu mimaride `Logstash` Ã§ok yorulur. Ã‡Ã¼nkÃ¼ herkes sadece `Logstash`'e data (log) yollar. Burada yÃ¼kÃ¼ daÄŸÄ±tmak iÃ§in `Beats` isimli uygulama sÄ±kÃ§a kullanÄ±lÄ±r. TÃ¼m projemizdeki her uygulama iÃ§in ayrÄ± ayrÄ± `Beats` ayaÄŸa kaldÄ±rabilir yada n-adet uygulama iÃ§in sadece 1 adet `Beats` kaldÄ±rabiliriz. `Beats` sadece aracÄ±lÄ±k yapar. `Logstash`'e bilgileri yollarken, `backpressure` yeteneÄŸi de olduÄŸundan yoÄŸunluk sÄ±rasÄ±nda sistemin dengesini korur. `Beats` aynÄ± zamanda isterse direk olarak `Elasticsearch`'e de aldÄ±ÄŸÄ± bilgileri atabilir. Hatta bazÄ± ek modÃ¼ller sayesinde basit filtreleme iÅŸlemleri de yapabilir.

`Beats`'ler tipine gÃ¶re farklÄ± executable dosyalarÄ± indirme gerektiriyor. aÅŸaÄŸÄ±daki tÃ¼m Ã¶rnek `Beats` uygulamalarÄ±, o anda Ã§alÄ±ÅŸtÄ±klarÄ± OS'tan toplandÄ±klarÄ± data'larÄ± Logstash veya `ElasticSearch`'e yollarlar.

- __Filebeat__

  istediÄŸimiz dosyalardan okuma yapar.

- __Winlogbeat__

  MS Windows log sisteminden log'larÄ± takip eder.

- __Auditbeat__

  `Linux Audit Framework` sisteminden topladÄ±ÄŸÄ± audit bilgilerini toplar.
  
  `Linux Audit Framework`, `Linux`'ta zaten varolan bir yapÄ±. son kullanÄ±cÄ±nÄ±n yaptÄ±ÄŸÄ± iÅŸlemleri tutmaktadÄ±r.

- __packetbeat__

  Ã‡alÄ±ÅŸtÄ±ÄŸÄ± `OS`'taki tÃ¼m diÄŸer process'lerin ne kadar `HTTP`, `DNS` isteÄŸi yaptÄ±ÄŸÄ± gibi bilgileri toplar.

- __Metricbeat__

  desteklediÄŸi birÃ§ok yazÄ±lÄ±mdan (`MongoDB`, `Redis`, `Zookeeper` gibi) metric toplar.

Logstash config dosyasÄ±nÄ±n kendine has bir syntax'Ä± var.

## ğŸ“Œ Syslog

Ã¶zel isimdir.

`Syslog` servisi, default'ta 514 portundan dinleme yapar. isteyen uygulamalar buraya log'larÄ±nÄ± yollar.

`Syslog` ekosistemi 3 parÃ§aya bÃ¶lebiliriz:

- `Syslog` mesaj formatÄ±

  log mesajÄ±nda hangi bilgilerin olacaÄŸÄ± modelidir.

  2 sÃ¼rÃ¼mÃ¼ var: 1-`RFC 3164` ve 2-`RFC 5424`.

- `Syslog` protocol

  servisinin network Ã¼zerinden nasÄ±l mesajÄ± alacaÄŸÄ± protocol'Ã¼ (Ã¶rnek `TCP` ve `UDP` var) farklÄ± `RFC`'lerde yazmaktadÄ±r.

- `Syslog` servisi (server)

  yukarÄ±daki 2 maddeyi dÃ¶kÃ¼mante etmiÅŸ olmalÄ±dÄ±r ki, `Syslog` server'a mesaj atacak olan yazÄ±lÄ±m uyumlu Ã§alÄ±ÅŸsÄ±n.

## ğŸ“Œ apps for syslog

- `rsyslog` ve `syslog-ng`, `syslog` server'larÄ±dÄ±r.

- `systemd-journald`

  piyasada buna sadece `journald` dendiÄŸi de olur.
  
  `systemd` projesinin bir parÃ§asÄ±dÄ±r ve onunla Ã§alÄ±ÅŸmak iÃ§in tasarlanmÄ±ÅŸtÄ±r.

  `systemd-journald` yazÄ±lÄ±mÄ± birÃ§ok farklÄ± yerden manuel olarak log'larÄ± toplar ve bir yerde birleÅŸtirir.

  `libc`'nin `syslog` fonskiyonu Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda, fonskiyon bir `UNIX domain socket`'e log'larÄ± `syslog` formatÄ±nda yollar. `libc`, bu log'larÄ± kimin okuyacaÄŸÄ±na karÄ±ÅŸmaz. Ã–rneÄŸin; bu `UNIX domain socket`'ten `systemd-journald` okuma yapar.

## ğŸ“Œ syslog format

`syslog` formatÄ±nda, sadece hangi alanlar (field'lar) olacaÄŸÄ± bellidir.

2 adet `syslog` formatÄ±nda log Ã¶rneklersek:

```text
<24>1 2025-01-12T11:22:33Z myHostName myService1 1111 2222 - merhaba1
<24>1 2025-01-12T11:22:33Z myHostName myService1 1111 3333 [example@32473 user="john" ip="10.0.0.5"] merhaba2
```

- 24: mail system olduÄŸunu ve log level'Ä±n bir sabit sayÄ± ile Ã§arpÄ±mÄ±dÄ±r (hesaplama formÃ¼lÃ¼ var `RFC`'de)

- 1: versiyonu temsil eder. Åu ana dek sadece 1 versiyon yayÄ±mlanmÄ±ÅŸtÄ±r.

- Zaman formatÄ± `ISO 8601` olmalÄ±dÄ±r.

- `1111` burada process ID'dir.

- `2222` ve `3333` mesajÄ±n tekil ID'sidir.

- KÃ¶ÅŸeli parantez iÃ§inde kalan kÄ±sÄ±m custom alanlardÄ±r. Ä°stediÄŸimiz oraya ekleyebiliriz. Bunlar RFC'de opsiyoneldir.

- Tire karakteri opsiyonel data olmadÄ±ÄŸÄ±nÄ± gÃ¶sterir.

## ğŸ“Œ syslog protocol

Network protocol tarafÄ±nda bu log `string`'i karÅŸÄ± tarafa taÅŸÄ±nmaktadÄ±r. RFC'ler okunduÄŸunda protocol'lerin Ã§ok saf olduÄŸu gÃ¶rÃ¼lÃ¼r. Yani `TCP` soket aÃ§Ä±p log'larÄ± yollamamÄ±z bile yeterlidir. Ek bir metadata yoktur. Sadece her log satÄ±rÄ± sonunda satÄ±r sonu karakterini eklememiz yeterli.

Bu sebeple; `Logstash` output plugin'i ile `syslog` server'Ä±na log atmak istediÄŸimiz zaman, saf `TCP` output plugin'ini kullanmamÄ±z yeterli olmaktadÄ±r. Burada sadece dikkat etmemiz gereken nokta: her log sonrasÄ± satÄ±r sonu karakteri eklemeliyiz. Bunu da `TCP` output plugin'inin `json_lines` codec'ini kullanmamÄ±z gerekiyor. Bu codec'in `JSON Lines` ile alakasÄ± yok. BambaÅŸka konulardÄ±r.

## ğŸ“Œ Syslog (Input plugin) for Logstash or Fluentd 

`Logstash` veya `Fluentd` ayarlarÄ±nda input plugin olarak `Syslog` aktif edilirse, `Logstash` veya `Fluentd`, 514 UDP portundan dinleme yapmaya baÅŸlar. aynÄ± bir `Syslog` daemon'u gibi log'larÄ± dinler ve bunlarÄ± `Elasticsearch`'e yollar.

`Linux`'ta Ã§alÄ±ÅŸan bazÄ± `syslog` daemon implementasyonlarÄ± hem kendileri mesajlarÄ± okuyor ve daha sonra ona gelen mesajlarÄ± baÅŸka porta yÃ¶nlendirebiliyor. BÃ¶yle olunca hem `Linux`, hemde `Fluentd` mesajlarÄ± okuyabiliyor.

## ğŸ“Œ OpenSearch

`Open Distro`, `OpenSearch` olarak ismi deÄŸiÅŸti.

`OpenSearch` sadece aÅŸaÄŸÄ±daki projeleri yeni isimlerle daha Ã¶zgÃ¼r lisans ile fork'ladÄ±:

- `Kibana` - `OpenSearch Dashboards`
- `ElasticSearch` - `OpenSearch`

`Logstash` ve `Beats` projeleri fork'lamadÄ±. Ã‡Ã¼nkÃ¼ zaten onlarla uyumlu Ã§alÄ±ÅŸmaktadÄ±r.

## ğŸ“Œ Kibana

`ElasticSearch`'teki data'larÄ± son kullanÄ±cÄ±ya gÃ¶stermek iÃ§in web arayÃ¼zÃ¼ sunan bir yazÄ±lÄ±m.

`Logstash` kendi internal'da kullandÄ±ÄŸÄ± config'lerini:

- index patterns
- saved searches
- saved visualizations
- ve dahasÄ±...

`ElasticSearch`'te farklÄ± bir index'e (RDBMS'teki tabloya denk gelen yapÄ±ya) kaydeder.

`Kibana` `Web UI`'Ä±ndaki sekmeler:

- `discover`: arama yapÄ±lmasÄ±nÄ± saÄŸlÄ±yor.
  `discover` sekmesindeki alt widget'lar:
  - bir widget'ta `Selected Fields` ve `Available Fields`. bunlar arama sonuÃ§larÄ± ekranÄ±nda gÃ¶sterilebilecek sÃ¼tunlarÄ± belirtmektedir. Ã¶rnek: "Available Fields" listesinde, log'larda akan tÃ¼m alanlar(sutunlar) mevcuttur. Ã¶rnek: appName, IP, timestamp, message. `Selected Fields` listesine, "Available Fields" listesinden seÃ§im yaparak alan ekleriz(taÅŸÄ±rÄ±z). bÃ¶ylece sadece `Selected Fields` listesindeki alanlarÄ±mÄ±z, sonuÃ§ ekranÄ±nda gÃ¶rÃ¼nmÃ¼ÅŸ olur. eÄŸer `Selected Fields` listesini boÅŸ bÄ±rakÄ±rsak sonuÃ§ ekranÄ±nda `\_source` sÃ¼tunu olur ve bu sÃ¼tunda tÃ¼m log bilgileri(alanlarÄ±) bir JSON ÅŸeklinde gÃ¶sterilir.
  - bir widget'ta standart olan "__Apache Lucene Query Syntax__" veya "__Kibana Query Language (âŸ· KQL)__" ile arama yapabilmemizi saÄŸlayan textbox mevcuttur. `Lucene` arama Ã¶rneÄŸi: `status:200 AND appName:user-service`. (`Lucene Query Syntax` baÅŸka baÅŸlÄ±kta detaylÄ± anlatÄ±lÄ±yor)
  - bir widget'ta filter'lar mevcut. bunlar `Lucene` stili aramasÄ±na ek filtreler eklememizi saÄŸlÄ±yor. `Lucene` ile de yapÄ±labilecek bir ÅŸey fakat filtreler kolay enable disable edilebiliyor. oysa `Lucene`'de bir filtreyi yorum satÄ±rÄ± yapmazsÄ±nÄ±z. silip tekrar yazmamÄ±z gerekir.

  Ekranda yaptÄ±ÄŸÄ±mÄ±z her ayar URL'ye yansÄ±r. URL'yi baÅŸka tarayÄ±cÄ±ya yapÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mÄ±zda bu arama aynen aÃ§Ä±lÄ±r.

- `dev tools`: JSON query'leri ile arama yapÄ±lmasÄ±nÄ± saÄŸlÄ±yor. Ã¶rnek:

```text
GET _search
{
  "query": {
    "match_all": {}
  }
}
```

- `visualize`: grafikler hazÄ±rlamamÄ±zÄ± saÄŸlÄ±yor. buradan grafik oluÅŸturuyoruz. fakat bu grafikleri direk `Web UI`'Ä± aÃ§an user'a gÃ¶steremiyoruz. bu grafikleri dashboard'a baÄŸlamak zorundayÄ±z.

- `dashboard`: bir filtre yazÄ±yoruz ve visualize'da hazÄ±rladÄ±ÄŸÄ±mÄ±z her gÃ¶rsel'i buradaki filtreye baÄŸlÄ±yoruz. Ã¶rneÄŸin filtremiz `status:200` olsun. altÄ±nda da buna baÄŸlÄ± 3 tane grafik baÄŸlamÄ±ÅŸ oluruz. bu `dashboard`'a "baÅŸarÄ±lÄ± istekler" adÄ±nÄ± verelim. birÃ§ok `dashboard`'umuz olabilir. artÄ±k `dashboard` sekmesine girip, listeden "baÅŸarÄ±lÄ± istekler" `dashboard`'Ä±nÄ± seÃ§en user, karÅŸÄ±sÄ±nda 3 tane grafik gÃ¶recektir.

## ğŸ“Œ Kibana index pattern

index `Elasticsearch`'te RDBMS'teki tabloya denk gelen bir terimdir.

`index pattern` tell `Kibana` which `ElasticSearch` `indices` you want to explore. An `index pattern` can match the name of a single `index`, or include a wildcard (`*`) to match multiple `indices`.

For example, `Logstash` typically creates a series of `indices` in the format `Logstash-YYYY.MMM.DD`.

## ğŸ“Œ index terimi karmaÅŸasÄ±

`index pattern`'i kibana kullanÄ±yor.

buradaki `index`, data'daki her field'Ä±n `index`'lenip `index`'lenmemesi ile alakalÄ± bir durum deÄŸil. baÄŸÄ±msÄ±z konular.

`elasticsearch`'te `index` bazen timestamp kullanÄ±lÄ±yor. bu otomatik olan bir durum deÄŸildir. manuel developer bu ÅŸekilde ayarlar. tablo ismini manuel timestamp vermiÅŸisiz anlamÄ±na gelir.

## ğŸ“Œ Kibana Query Language (KQL)

`Lucene syntax`'Ä±na benzemektedir. `Lucene syntax`'Ä±nÄ±n sunmadÄ±ÄŸÄ± ek Ã¶zellikler sunmaktadÄ±r.

## ğŸ“Œ ElasticSearch Query DSL

API Ã¼zerinden sunulan query sorgulama JSON syntax'Ä±dÄ±r. TÃ¼m `ElasticSearch` API'si `Query DSL` deÄŸildir. `Query DSL` sadece `query` field'Ä± iÃ§indeki syntax'a verilen isimdir.

```text
GET /_search
```

```json
{
    "query": {
        "match" : {
            "message" : {
                "query" : "this is a test"
            }
        }
    }
}
```

## ğŸ“Œ Graylog

`Graylog`; `Logstash` ve `Kibana`'ya alternatif, `ELK`'ya gÃ¶re daha community based bir projedir.

`Graylog` genelde `ElasticSearch` ve `MongoDB` ile kullanÄ±lÄ±yor. `MongoDB`'de genel `graylog`'un config'leri saklanÄ±rken, `ElasticSearch`'te log'larÄ±n kendileri saklanÄ±yor.

`Graylog` sunucusuna direk mesajlarÄ± atabiliriz. Fakat `Beats` veya `Logstash` ile de ek modÃ¼llerle support'u mevcut.

## ğŸ“Œ Fluentd

ayrÄ± bir process olarak Ã§alÄ±ÅŸÄ±r.

2 gÃ¶revi var diyebiliriz:
- `Logstash`'e alternatiftir.
- `beats`'e alternatiftir. Fakat FLuentd burada kullanmak gereksiz olur. Burada `Fluentbit` Ã¶nerilir. Ã§Ã¼nkÃ¼ daha hafiftir ve `Fluentbit` sadece agent modu iÃ§in tasarlanmÄ±ÅŸtÄ±r.

- sadece `Beats` yerine de koyabiliriz
- sadece `logstash` yerine de koyabiliriz.
- `Logstash`'e de direk log yollayabilir, `elasticsearch`'e de direk yollayabilir. Yani sadece kendi baÅŸÄ±na da iÅŸi baÅŸtan sona tamamlayabiliyor.

`JDK` baÄŸÄ±mlÄ±lÄ±ÄŸÄ± yok.

## ğŸ“Œ Vector

`Fluentd` ve `Fluentbit` ikilisine birlikte alternatiftir. ikisini gÃ¶revini gÃ¶rÃ¼r.

## ğŸ“Œ Splunk

Ticari lisansla daÄŸÄ±tÄ±lan merkezi bir log yÃ¶ntim sistemidir. TÃ¼m sistemi baÅŸtan sona iÃ§inde barÄ±ndÄ±rÄ±r.

â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢

â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢

â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢

## ğŸ“Œ Log driver of Docker

`Docker` runtime sÄ±rasÄ±nda sysout ve syserr Ã§Ä±ktÄ±larÄ±nÄ± container dÄ±ÅŸÄ±nda herhangi bir yere yÃ¶nlendirebilir. driver seÃ§eneÄŸini container baÅŸlatÄ±nca verebiliriz. Ã¶rnekler:

- `none`

  hiÃ§ log basmaz.

- `json-file`

  container dÄ±ÅŸÄ±nda (`docker`'Ä± run eden `OS` iÃ§inde) bir `JSON` dosyaya kaydeder.

- `local`

  container dÄ±ÅŸÄ±nda (`docker`'Ä± run eden `OS` iÃ§inde) bir dosyaya kaydeder.

- `syslog`

  `docker`'Ä± run eden `OS`'un syslog servisine log'larÄ± yollar.

- `fluentd`

  `fluentd` servisine log'larÄ± yollar.

â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢

â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢

â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢

## ğŸ“Œ Solr vs ElasticSearch

Ikisi de aÃ§Ä±k kaynaklÄ± birbirine alternatif arama index'leyici ve query yazÄ±lÄ±mlardÄ±r.

`Solr`'da field isimleri ve field type'lar baÅŸtan belirtilmek zorundadÄ±r. Yeni field eklemeye kalktÄ±ÄŸÄ±nÄ±zda, bÃ¼tÃ¼n kayÄ±tlarÄ± tekrar `Solr`'a aktarmanÄ±z gerekiyor. `Elasticsearch`'te bÃ¶yle bir durum yok. Ã‡Ã¼nkÃ¼ `Elasticsearch`, scheme barÄ±ndÄ±rmÄ±yor. `NoSQL` `DB` gibi.

â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢

â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢

â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢

## ğŸ“Œ ElasticSearch

`elastic`, yazÄ±lÄ±mÄ± geliÅŸtiren firmanÄ±n adÄ±. firmanÄ±n eski ismi `ElasticSearch`'tÃ¼.

`ElasticSearch` document based (`MongoDB` gibi) data storage'tÄ±r. JSON formatÄ±nda saklar. fakat dÃ¶kÃ¼manÄ±n her parÃ§asÄ±nÄ± index'ler.

bu index'leme tekniÄŸi birÃ§ok arama motoru kullanÄ±r ve buna `inverted Index` denir. Ã¶rneÄŸin;

3 adet kaydÄ±mÄ±z olsun:

```text
dÃ¶kÃ¼man numarasÄ± - iÃ§eriÄŸindeki kelimeler
1- a b c
2- x y z
3- a x
```

`Elasticsearch` ÅŸu ÅŸekilde index tutar:

```text
a -> 1, 3
b -> 1
c -> 1
x -> 2, 3
y -> 2
z -> 2
```

`x` terimini arattÄ±ÄŸÄ±mÄ±zda direk 2 ve 3Ã¼ncÃ¼ `document`'lerde olduÄŸunu bulmamÄ±zÄ± saÄŸlar.

`inverted index` teriminin tersi `Forward Index` terimidir. yani her dÃ¶kÃ¼man sadece `tokenizing` edilir. index'lenmiÅŸ olur. performansa tek katkÄ±sÄ± zaten `tokenizing` edilmiÅŸ olmasÄ±dÄ±r. parse edilmesine gerek yoktur.

`inverted Index` kabaca yukarÄ±daki gibi bir matris tutar. spesifik implementasyonlarÄ± bakarsak farklÄ± bilgiler de iÃ§erebilir. Ã¶rnekler:

- her kelimenin dÃ¶kÃ¼manda kaÃ§ kere yer aldÄ±ÄŸÄ± bilgisi
- kelimenin dÃ¶kÃ¼mandaki pozisyonu

`ElasticSearch` dÄ±ÅŸarÄ±ya `REST` `API` sunar, bu dilden baÄŸÄ±msÄ±z sorgu atabilmemizi saÄŸlar.

### ğŸ“ŒğŸ“Œ shard

kelime anlamÄ±: parÃ§a

`Elasticsearch`'in tuttuÄŸu her index tek bir makinede tutulmayabilir. onu partition'lara ayÄ±rabiliriz. ayÄ±rdÄ±ÄŸÄ±mÄ±z her partition'a shard denir.

1 `node`'a, `shard` dememek gerekli. Ã§Ã¼nkÃ¼ 1 `node`, 1'den fazla `shard` iÃ§erebilir ve aynÄ± zamanda `replica` gÃ¶revi de gÃ¶rebilir.

### ğŸ“ŒğŸ“Œ replica

her `shard`'Ä±n tutulacaÄŸÄ± `replika` `node`'lara verilen isimdir.

### ğŸ“ŒğŸ“Œ index

`RDBMS`'deki tablo'ya denk gelen kavramdÄ±r. en Ã¼st seviye bilgi grubudur. her index'e bir alias atÄ±lmak zorunda deÄŸildir. fakat atÄ±lmasÄ± mutlaka Ã¶nerilir. bir sistemde min 1 index olmalÄ±dÄ±r.

### ğŸ“ŒğŸ“Œ Indices (âŸ· indexes)

`index` teriminin Ã§oÄŸul hali olduÄŸundan, `RDBMS` server'larÄ±ndaki, DB'ye denk geliyor diyebiliriz. Ã§Ã¼nkÃ¼; birden fazla index yani tablo bir DB'i tanÄ±mlar.

### ğŸ“ŒğŸ“Œ Mapping

`RDBMS`'deki ÅŸemaya denk gelir. istenirse tipler Ã¶nceden mapping ile belirtilebiliyor.

fakat ElasticSearch yeni bir kayÄ±t eklendiÄŸinde verinin yapÄ±sÄ±nÄ± zaten tespit ediyor.

### ğŸ“ŒğŸ“Œ Document

`RDBMS`'deki tablo iÃ§indeki kayda (row) denk gelir.

### ğŸ“ŒğŸ“Œ Type

Document'in tipini belirtir. user, tweet tipinde farklÄ± document'ler olabilir. `RDBMS`'deki tablo'ya denk gelir.

### ğŸ“ŒğŸ“Œ field

`RDBMS`'deki her tablo iÃ§inde olan bir sÃ¼tuna denk gelir. `Elasticsearch`, `NoSQL` olduÄŸu iÃ§in `JSON` tutar ve her field bir JSON property'dir.

### ğŸ“ŒğŸ“Œ kayÄ±t eklemek

`ElasticSearch` Ã¶nceden ÅŸema istemediÄŸinden attÄ±ÄŸÄ±mÄ±z yeni kaydÄ± direk kabul eder ve bundan arama yapÄ±labilmesini kendisi saÄŸlar. yeni kaydÄ±mÄ±zÄ± Rest API'si ile ekleyelim:

> PUT ELASTIC_SEARCH_URL/customer/_doc/1

```json
{
  "name": "John Doe"
}
```

dÃ¶nÃ¼ÅŸÃ¼:

```json
{
  "_index" : "customer",
  "_type" : "_doc",
  "_id" : "1",
  "_version" : 1,
  "result" : "created",
  "_shards" : {
    "total" : 2,
    "successful" : 2,
    "failed" : 0
  },
  "_seq_no" : 26,
  "_primary_term" : 4
}
```

ÅŸimdi kaydÄ±mÄ±zÄ± Ã§ekelim:

```
GET /customer/_doc/1
```

dÃ¶nÃ¼ÅŸÃ¼:

```json
{
  "_index" : "customer",
  "_type" : "_doc",
  "_id" : "1",
  "_version" : 1,
  "_seq_no" : 26,
  "_primary_term" : 4,
  "found" : true,
  "_source" : {
    "name": "John Doe"
  }
}
```

BirÃ§ok dÃ¶kÃ¼man index'lenecek ise, tek tek yerine performans aÃ§Ä±sÄ±ndan `_bulk` `API`'si tercih edilmelidir.

BirÃ§ok kayÄ±t index'lemiÅŸ olalÄ±m. Åimdi bu kayÄ±tlarÄ±mÄ±zÄ± arayalÄ±m:

```
GET /bank/_search
```

```json
{
  "query": { "match_all": {} },
  "sort": [
    { "account_number": "asc" }
  ]
}
```

dÃ¶nÃ¼ÅŸÃ¼:

```json
{
  "took" : 63, //how long it took ElasticSearch to run the query, in milliseconds
  "timed_out" : false, // request timeout or not.
  "_shards" : { // how many shards were searched and a breakdown of how many shards succeeded, failed, or were skipped
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
        "value": 1000,
        "relation": "eq"
    },
    "max_score" : null,
    "hits" : [ {
      "_index" : "bank",
      "_type" : "_doc",
      "_id" : "0",
      "sort": [0],
      "_score" : null,
      "_source" : {"account_number":0,"balance":16623,"firstname":"Bradshaw","lastname":"Mckenzie","age":29,"gender":"F","address":"244 Columbus Place","employer":"Euron","email":"bradshawmckenzie@euron.com","city":"Hobucken","state":"CO"}
    }, {
      "_index" : "bank",
      "_type" : "_doc",
      "_id" : "1",
      "sort": [1],
      "_score" : null,
      "_source" : {"account_number":1,"balance":39225,"firstname":"Amber","lastname":"Duke","age":32,"gender":"M","address":"880 Holmes Lane","employer":"Pyrami","email":"amberduke@pyrami.com","city":"Brogan","state":"IL"}
    },
    //...
    ]
  }
}
```

â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢

â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢

â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢

## ğŸ“Œ Nested objects

`ElasticSearch` stores:

- the inner (nested) `JSON` objects as different (separate) documents. The data type of these documents are nested type. The standard document type is `object`.

```json
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "user": {
        "type": "nested"
      }
    }
  }
}

PUT my-index-000001/_doc/1
{
  "group" : "fans",
  "user" : [
    {
      "first" : "John",
      "last" :  "Smith"
    },
    {
      "first" : "Alice",
      "last" :  "White"
    }
  ]
}

GET my-index-000001/_search
{
  "query": {
    "nested": {
      "path": "user",
      "query": {
        "bool": {
          "must": [
            { "match": { "user.first": "Alice" }},
            { "match": { "user.last":  "Smith" }}
          ]
        }
      }
    }
  }
}
```

- the arrays as a flattened format.

```json
PUT my-index-000001/_doc/1
{
  "group" : "fans",
  "user" : [
    {
      "first" : "John",
      "last" :  "Smith"
    },
    {
      "first" : "Alice",
      "last" :  "White"
    }
  ]
}
```

It stores internally as:

```json
{
  "group" :        "fans",
  "user.first" : [ "alice", "john" ],
  "user.last" :  [ "smith", "white" ]
}
```

We can query using:

```json
GET my-index-000001/_search
{
  "query": {
    "bool": {
      "must": [
        { "match": { "user.first": "Alice" }},
        { "match": { "user.last":  "Smith" }}
      ]
    }
  }
}
```

â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢

â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢

â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ â€¢

## ğŸ“Œ ElasticSearch vs Cassandra vs MongoDB

Elasticsearch bir search ve analytics engine'i iken, diÄŸerleri NoSQL olarak geÃ§mektedir. 3 alternatif yazÄ±lÄ±m data'larÄ± NoSQL olarak hard-drive'a kaydedip, bunlarÄ± client'a sunsalar da, tutuÅŸ biÃ§imleri performans Ã¶nceliklerine gÃ¶re deÄŸiÅŸmektedir.

MongoDB generic-purpose bir NoSQL DB olarak kullanÄ±lÄ±r. istediÄŸimiz sÃ¼tunlarÄ± index'leriz. Cassandra'da ise, sorgularÄ±mÄ±z baÅŸtan belli olmalÄ±dÄ±r ve daha incremental data'larÄ±n kaydÄ± iÃ§in kullanÄ±lÄ±r. ElasticSearch ise tÃ¼m sÃ¼tunlarÄ± (field'larÄ±) ve field'larÄ±n iÃ§indeki data'larÄ± sÃ¼rekli index'ler. bu ÅŸekilde tÃ¼m data'larda hÄ±zlÄ± arama yapÄ±labilmesini saÄŸlar. fakat bu durum insert iÅŸlemlerini yavaÅŸlatÄ±r, Ã§Ã¼nkÃ¼ her insert iÅŸleminde index'leme Ã§alÄ±ÅŸmasÄ± ÅŸarttÄ±r (ve tÃ¼m field'lar index'lenmek zorundadÄ±r).

ElasticSearch "document store" olarak kayÄ±t tutmaktadÄ±r.

ElasticSearch ek olarak "__full-text search__" destekleyen bir storage'dir. "full-text search" teriminin kapsamÄ± keskin Ã§izgilerle Ã§izilmemiÅŸtir. SQL'deki "like" keyword'Ã¼ de text search Ã¶zelliÄŸidir, fakat "full-text search" birÃ§ok kompleks Ã¶zelliÄŸi kapsar. bunlardan bazÄ±larÄ±:

- __stop word__'lerin otomatik Ã§Ä±karÄ±lmasÄ± ("and", "I" gibi kelimeler...)
- kelime kÃ¶klerinin algÄ±lanmasÄ±nÄ± saÄŸlamak. Ã¶rnek: "git" arandÄ±ÄŸÄ±nda, "gidiyorum" kelimesi iÃ§eren sonuÃ§larda bulunur.
- petabyte'lar Ã¼zerinden arama yapabilmek
- birden fazla sÃ¼tunu birleÅŸtirerek arama yapabilmek (ve hatta bu sÃ¼tunlarÄ±n bazÄ±larÄ± farklÄ± tipte olabilirken (Ã¶rnek: char, varchar...))
- tÃ¼m bu Ã¶zelliklerin opsiyonel olabilmesi
